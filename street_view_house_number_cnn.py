# -*- coding: utf-8 -*-
"""Street View House Number CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gsa3gbE3hpu8GwqFAKtGBPxmlYRFKIUz

#Developing a Convolutional Neural Network (CNN) Model for Accurate House Number Classification in the SVHN Dataset: Importance and Applications

##Project Description
The main goal of this project is to develop a CNN model capable of accurately classifying house numbers in the Street View House Numbers (SVHN) dataset. The SVHN dataset consists of images containing house numbers from real-world scenarios, such as street addresses, storefronts, and building exteriors.

##Data Description

###Key Features:
1. Image Format: The dataset consists of RGB images in a variety of sizes and aspect ratios. Each image represents a real-world scene containing one or more house numbers.

2. Labeling: The dataset provides accurate bounding box information and label annotations for the digits present in each image. This information allows for precise digit localization and classification.
3. Multi-digit Numbers: The SVHN dataset includes images with single-digit numbers as well as those with multiple digits. The dataset provides information about the location, order, and labeling of each digit within a multi-digit number.
4. Large-Scale Dataset: The SVHN dataset is relatively large, containing tens of thousands of labeled images for training, validation, and testing. It offers a diverse range of real-world scenarios, capturing variations in fonts, colors, backgrounds, and digit appearance.
5. Training, Validation, and Testing Sets: The dataset is typically divided into three separate sets: a training set used to train the model, a validation set used for hyperparameter tuning and model selection, and a testing set for evaluating the model's performance on unseen data.
6. Class Distribution: The SVHN dataset is typically labeled with the digits 0-9 as the classes. The dataset's class distribution ensures a balance of examples for each digit, providing equal representation across the different digits.

The SVHN dataset serves as a valuable resource for developing and evaluating models for digit recognition, multi-digit classification, and address-related tasks. It offers a realistic and challenging dataset that reflects the complexity and variations encountered in real-world house number recognition scenarios.
"""

import tensorflow as tf
import tensorflow_datasets as tfds

# Load the SVHN dataset
svhn_dataset, svhn_info = tfds.load('svhn_cropped', split='train', with_info=True)

# Split the dataset into train and test sets
train_percentage = 0.8
num_train_examples = int(train_percentage * svhn_info.splits['train'].num_examples)

train_dataset = svhn_dataset.take(num_train_examples)
test_dataset = svhn_dataset.skip(num_train_examples)

# Extract x_train, y_train, x_test, y_test
x_train, y_train = [], []
x_test, y_test = [], []

for example in train_dataset:
    x_train.append(example['image'])
    y_train.append(example['label'])

for example in test_dataset:
    x_test.append(example['image'])
    y_test.append(example['label'])

"""###Visualizing the images

"""

import matplotlib.pyplot as plt
# Extract a sample image and its label
# Extract 10 sample images and labels
sample_dataset = svhn_dataset.take(100)

# Display the images
fig, axes = plt.subplots(10, 10, figsize=(12, 6))
axes = axes.flatten()

for i, sample in enumerate(sample_dataset):
    image = sample['image']
    label = sample['label']

    # Convert image to numpy array
    image = image.numpy()

    # Display the image
    axes[i].imshow(image)
    axes[i].set_title(f"Label: {label}")
    axes[i].axis('off')

plt.tight_layout()
plt.show()

"""### Split the dataset to train, test data and preprocessing the data"""

# Convert the lists to TensorFlow tensors
x_train = tf.stack(x_train)
y_train = tf.stack(y_train)
x_test = tf.stack(x_test)
y_test = tf.stack(y_test)

# Convert x_train and x_test to float32
x_train = tf.cast(x_train, tf.float32)
x_test = tf.cast(x_test, tf.float32)

# Normalize pixel values
x_train = x_train / 255.0
x_test = x_test / 255.0

x_train.shape

x_test.shape

import numpy as np
unique_values = np.unique(y_train.numpy())
num_unique_values = len(unique_values)
print(num_unique_values)

from tensorflow.keras.utils import to_categorical

# Convert y_train to one-hot encoded format
num_classes = 10
y_train_encoded =to_categorical(y_train, num_classes)


y_test_encoded = to_categorical(y_test, num_classes)

y_train_encoded.shape

import tensorflow.keras as keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import TensorBoard

cnn_model = Sequential()

# Convolutional layers
cnn_model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))
cnn_model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))
cnn_model.add(MaxPooling2D(pool_size=(2, 2)))
cnn_model.add(Dropout(0.3))

cnn_model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))
cnn_model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))
cnn_model.add(MaxPooling2D(pool_size=(2, 2)))
cnn_model.add(Dropout(0.3))

# Flatten the output from the previous layer
cnn_model.add(Flatten())

# Dense (fully connected) layers
cnn_model.add(Dense(512, activation='relu'))
cnn_model.add(Dense(512, activation='relu'))

# Output layer
cnn_model.add(Dense(10, activation='softmax'))

cnn_model.compile(loss="categorical_crossentropy", optimizer='adam', metrics=["accuracy"])

history = cnn_model.fit(x_train, y_train_encoded, epochs = 6, batch_size = 32, shuffle = True, validation_data=[x_test, y_test_encoded])

prediction = cnn_model.predict(x_test)
prediction = np.argmax(prediction, axis =1)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.ylabel("")

from sklearn.metrics import classification_report
print(classification_report(prediction, y_test))

# Extract a sample of 50 images and labels
sample_dataset = svhn_dataset.take(50)

# Make predictions on the sample dataset
predictions = cnn_model.predict(x_train[:50])
predicted_labels = [np.argmax(pred) for pred in predictions]

# Display the images with their true labels and predicted labels
fig, axes = plt.subplots(5, 10, figsize=(15, 8))

for i, sample in enumerate(sample_dataset):
    image = sample['image']
    true_label = sample['label']
    predicted_label = predicted_labels[i]

    # Convert image to numpy array
    image = image.numpy()

    # Display the image with true label and predicted label
    axes[i // 10, i % 10].imshow(image)
    axes[i // 10, i % 10].set_title(f"True: {true_label}\nPredicted: {predicted_label}")
    axes[i // 10, i % 10].axis('off')

plt.tight_layout()
plt.show()







